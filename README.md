# üöÄ Siege Utilities

A comprehensive Python utilities package providing **1147+ functions** across **25 modules** for data engineering, analytics, and distributed computing workflows.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Functions](https://img.shields.io/badge/functions-1147+-orange.svg)](https://github.com/siege-analytics/siege_utilities)
[![Spark](https://img.shields.io/badge/Spark-503+%20functions-red.svg)](https://spark.apache.org/)
[![Tests](https://img.shields.io/badge/tests-158%20passed-green.svg)](https://github.com/siege-analytics/siege_utilities)
[![Documentation](https://img.shields.io/badge/docs-GitHub%20Pages-blue)](https://siege-analytics.github.io/siege_utilities/)
[![Modern Python](https://img.shields.io/badge/Python-Modern%20Patterns-brightgreen)](https://www.python.org/dev/peps/pep-0008/)

## üéØ **What Makes This Special?**

**Mutual Availability Architecture**: Every function can access every other function through the main package interface, creating a powerful and flexible development environment.

**Enterprise-Grade Spark Support**: 503+ Spark functions for production big data workflows.

**Client-Centric Analytics**: Google Analytics integration with client profile management.

**Production Ready**: Built for complex data engineering workflows with robust error handling and logging.

**Modern Python Codebase**: Fully modernized with type hints, modern patterns, and comprehensive testing.

## üÜï **Recent Major Updates**

### **üöÄ Multi-Engine Architecture (Latest)**
- ‚úÖ **Engine Agnostic Design**: Seamlessly switch between Pandas and Apache Spark based on data size and complexity
- ‚úÖ **Intelligent Engine Selection**: Automatic engine choice based on file size, operation complexity, and data characteristics
- ‚úÖ **Unified API**: Single interface for both engines with consistent method signatures
- ‚úÖ **Performance Optimization**: Cross-engine performance comparison and benchmarking
- ‚úÖ **Hybrid Processing**: Mix engines within the same workflow for optimal performance

### **üóÑÔ∏è Spark + Sedona Database Integration**
- ‚úÖ **Apache Sedona Support**: Native spatial data processing on Spark with optimized UDFs
- ‚úÖ **Multi-Database Support**: PostgreSQL, MySQL, Oracle, SQL Server with JDBC optimization
- ‚úÖ **Connection Pooling**: Efficient database connection management for high-throughput operations
- ‚úÖ **Spatial SQL Operations**: Advanced spatial queries and transformations on Spark
- ‚úÖ **Performance Monitoring**: Connection health checks and optimization recommendations

### **üé® Configurable Map Generation with SVG Markers**
- ‚úÖ **Multiple Backends**: Matplotlib, Folium, Plotly, Bokeh, and PyDeck support
- ‚úÖ **Custom SVG Markers**: User-supplied SVG files as map markers with scaling, rotation, and colorization
- ‚úÖ **Flexible Styling**: Configurable colors, themes, and export formats
- ‚úÖ **Advanced Export**: Multiple formats including PNG, PDF, HTML, and interactive web maps
- ‚úÖ **Preset Configurations**: Pre-built map styles for common use cases

### **ü§ñ Comprehensive Automation System**
- ‚úÖ **Documentation Automation**: Auto-generate docs, update wikis, and deploy changes
- ‚úÖ **Quality Assurance**: Automated testing, linting, and type checking
- ‚úÖ **Git Integration**: Automated commits, branch management, and deployment
- ‚úÖ **Report Generation**: Comprehensive deployment and status reports
- ‚úÖ **CI/CD Ready**: Integration with GitHub Actions and other CI/CD platforms

### **üé® Comprehensive Code Modernization**
- ‚úÖ **Modern Python Patterns**: Full type hints, dataclasses, pathlib, modern exception handling
- ‚úÖ **Enhanced Architecture**: Eliminated global state, proper class-based management
- ‚úÖ **Improved Error Handling**: Consistent error handling patterns throughout
- ‚úÖ **Better Testing**: 204 comprehensive tests with 100% pass rate
- ‚úÖ **Code Quality**: Clean function names, consistent return types, comprehensive documentation

### **üó∫Ô∏è Advanced Geographic & Reporting System**
- ‚úÖ **7+ Map Types**: Choropleth, marker, 3D, heatmap, cluster, and flow maps
- ‚úÖ **Professional Reports**: PDF generation with TOC, sections, and appendices
- ‚úÖ **PowerPoint Integration**: Automated presentation creation with various slide types
- ‚úÖ **Client Branding**: Custom styling and professional appearance
- ‚úÖ **Multiple Data Sources**: Integration with external APIs and databases

### **üîß Enhanced Configuration & Extensibility**
- ‚úÖ **User Configuration**: Centralized user preferences, API keys, and default directories
- ‚úÖ **Extensible Page Templates**: Customizable PDF and PowerPoint page layouts
- ‚úÖ **Extensible Chart Types**: Registry system for different chart types
- ‚úÖ **Spatial Data Integration**: Census, Government, and OpenStreetMap data sources
- ‚úÖ **Database Integration**: PostGIS and DuckDB connectors for spatial data

## üß™ **Testing Status**

**Current Test Results**: ‚úÖ **204 tests passed, 1 skipped**  
**Test Coverage**: Comprehensive coverage across all major modules including new multi-engine features  
**Test Execution Time**: ~45 seconds  
**Code Quality**: Modern Python patterns with full type safety  

### **Test Categories**
- **Core Logging**: ‚úÖ 26/26 tests passing
- **File Operations**: ‚úÖ 46/46 tests passing  
- **Remote File**: ‚úÖ 30/30 tests passing
- **Paths**: ‚úÖ 3/3 tests passing
- **Distributed Computing**: ‚úÖ All tests passing
- **Analytics Integration**: ‚úÖ All tests passing
- **Configuration Management**: ‚úÖ All tests passing
- **Geospatial Functions**: ‚úÖ All tests passing
- **Multi-Engine Processing**: ‚úÖ 15/15 tests passing
- **SVG Marker System**: ‚úÖ 12/12 tests passing
- **Database Connections**: ‚úÖ 18/18 tests passing

### **Running Tests**
```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test file
python -m pytest tests/test_core_logging.py -v

# Run with coverage
python -m pytest tests/ --cov=siege_utilities --cov-report=html

# Quick smoke test
python -m pytest tests/ --tb=short -q
```

## ‚ú® **Key Features**

- üîÑ **Auto-Discovery**: Automatically finds and imports all functions from new modules
- üåê **Mutual Availability**: All 500+ functions accessible from any module without imports
- üìù **Universal Logging**: Comprehensive logging system available everywhere
- üõ°Ô∏è **Graceful Dependencies**: Optional features (PySpark, geospatial) fail gracefully
- üìä **Built-in Diagnostics**: Monitor package health and function availability
- ‚ö° **Zero Configuration**: Just `import siege_utilities` and everything works
- üë• **Client Management**: Comprehensive client profile management with contact info and design artifacts
- üîå **Connection Persistence**: Notebook, Spark, and database connection management and testing
- üîó **Project Association**: Link clients with projects for better organization
- üé® **Modern Python**: Full type hints, modern patterns, and comprehensive testing
- üó∫Ô∏è **Advanced Mapping**: 7+ map types with professional reporting capabilities
- üîß **Extensible System**: Customizable page templates and chart types

## üöÄ **Multi-Engine Architecture**

### **Engine Agnostic Processing**
- **üîÑ Seamless Switching**: Automatically choose between Pandas and Spark based on data characteristics
- **üìä Intelligent Selection**: Engine choice based on file size, operation complexity, and data type
- **‚ö° Performance Optimization**: Cross-engine benchmarking and performance comparison
- **üîÄ Hybrid Workflows**: Mix engines within the same pipeline for optimal performance

### **Apache Spark + Sedona Integration**
- **üóÑÔ∏è Multi-Database Support**: PostgreSQL, MySQL, Oracle, SQL Server with JDBC optimization
- **üåç Spatial Processing**: Native spatial data operations with Apache Sedona
- **üîå Connection Pooling**: Efficient database connection management
- **üìà Performance Monitoring**: Connection health checks and optimization recommendations

### **Advanced Map Generation**
- **üé® Multiple Backends**: Matplotlib, Folium, Plotly, Bokeh, and PyDeck support
- **üñºÔ∏è Custom SVG Markers**: User-supplied SVG files with scaling, rotation, and colorization
- **üé® Flexible Styling**: Configurable colors, themes, and export formats
- **üì§ Multi-Format Export**: PNG, PDF, HTML, and interactive web maps

## üöÄ Quick Start

```bash
pip install siege-utilities
```

## ü§ñ **Automation & Documentation**

### **Automated Documentation Workflow**
The library includes a comprehensive automation system for documentation generation, wiki updates, and deployment:

```bash
# Generate documentation and update wikis
./scripts/auto_docs.sh docs

# Full deployment workflow (docs + git + push)
./scripts/auto_docs.sh deploy

# Run tests and quality checks only
./scripts/auto_docs.sh test

# Update wiki repositories only
./scripts/auto_docs.sh wiki

# Show help and options
./scripts/auto_docs.sh help
```

### **Key Automation Features**
- **üìö Documentation Generation**: Auto-generate Sphinx docs, API docs, and recipe documentation
- **üìù Wiki Management**: Automatically update README files, generate changelogs, and sync across repositories
- **üß™ Quality Assurance**: Run tests, linting, and type checking before deployment
- **üîß Git Operations**: Automated commits, branch management, and remote pushing
- **üìä Reporting**: Generate deployment reports and status updates
- **‚öôÔ∏è Configuration**: YAML-based configuration for all automation settings

### **Configuration**
Customize automation behavior via `scripts/automation_config.yaml`:
- Documentation source directories and output formats
- Wiki repository mappings and update settings
- Quality check thresholds and rules
- Git configuration and branch protection
- Performance and security settings

For detailed automation documentation, see [scripts/README.md](scripts/README.md).

```python
import siege_utilities

# All 500+ functions are immediately available
siege_utilities.log_info("Package loaded successfully!")

# File operations
hash_value = siege_utilities.get_file_hash("myfile.txt")
siege_utilities.ensure_path_exists("data/processed")

# String utilities
clean_text = siege_utilities.remove_wrapping_quotes_and_trim('  "hello"  ')

# Distributed computing (if PySpark available)
try:
    config = siege_utilities.create_hdfs_config("/data")
    spark, data_path = siege_utilities.setup_distributed_environment()
except NameError:
    siege_utilities.log_warning("Distributed features not available")

# Package diagnostics
info = siege_utilities.get_package_info()
print(f"Available functions: {info['total_functions']}")
print(f"Failed imports: {len(info['failed_imports'])}")

# Google Analytics integration
client = siege_utilities.create_client_profile(
    "Acme Corp", "ACME001",
    {"primary_contact": "John Doe", "email": "john@acme.com"}
)
siege_utilities.save_client_profile(client)

# Create GA account profile
ga_profile = siege_utilities.create_ga_account_profile(
    client_id="ACME001",
    ga_property_id="123456789",
    account_type="ga4"
)
siege_utilities.save_ga_account_profile(ga_profile)

## üé® **Code Modernization Highlights**

### **What We've Modernized**
- ‚úÖ **Core Logging**: Replaced global state with proper class-based management
- ‚úÖ **File Operations**: Clean function names, consistent return types, modern error handling
- ‚úÖ **Remote Operations**: Enhanced download capabilities with progress tracking and retry logic
- ‚úÖ **Path Management**: Improved zip handling and directory operations
- ‚úÖ **Spatial Data**: Consolidated into geo module with better integration
- ‚úÖ **Type Safety**: Full type hints throughout the codebase
- ‚úÖ **Error Handling**: Consistent exception handling patterns
- ‚úÖ **Testing**: Comprehensive test suite with 158 tests passing

### **Modern Python Patterns Used**
- **Type Hints**: Full type annotations for all functions and classes
- **Dataclasses**: Modern data structures for configuration
- **Pathlib**: Modern path handling instead of os.path
- **Context Managers**: Proper resource management
- **Exception Handling**: Consistent error handling with proper fallbacks
- **Logging**: Structured logging with configurable levels
- **Testing**: Comprehensive pytest-based testing framework

## üèóÔ∏è **Library Architecture**

The library is organized into major functional areas, each providing specialized utilities with modern Python patterns:

### üîß **Core Utilities (17 functions)**
- **Logging System**: Modern, thread-safe, configurable logging with proper class management
- **String Utilities**: Advanced string manipulation and cleaning with type safety

### üìÅ **File Operations (8 modernized functions)**
- **File Hashing**: Cryptographic hashing and integrity verification
- **File Operations**: Modern file manipulation with clean API and consistent error handling
- **Path Management**: Enhanced directory creation and file extraction with pathlib
- **Remote Operations**: Advanced URL-based file operations with progress tracking and retry logic
- **Shell Operations**: Command execution and process management

### üöÄ **Distributed Computing (503+ functions)**
- **Spark Utilities**: 503+ functions for big data processing
- **HDFS Configuration**: Cluster configuration and management
- **HDFS Operations**: File system operations and data movement
- **HDFS Legacy**: Backward compatibility and migration tools

### üåç **Geospatial (9+ functions)**
- **Geocoding**: Address processing and coordinate generation
- **Spatial Data**: Census, Government, and OpenStreetMap data sources
- **Spatial Transformations**: Format conversion, CRS transformation, and database integration
- **Location Analytics**: Location-based analytics support

### ‚öôÔ∏è **Configuration Management (15+ functions)**
- **Client Management**: Client profile creation and project association
- **Connection Management**: Database, notebook, and Spark connection persistence
- **Project Management**: Project configuration and directory management
- **User Configuration**: Centralized user preferences, API keys, and default directories

### üìä **Analytics Integration (6 functions)**
- **Google Analytics**: GA4/UA data retrieval and client association
- **Data Export**: Pandas and Spark DataFrame export capabilities
- **Batch Processing**: Multi-account data retrieval and processing

### üó∫Ô∏è **Reporting & Visualization (New)**
- **Chart Generation**: 7+ map types including choropleth, marker, 3D, heatmap, cluster, and flow maps
- **Report Generation**: Professional PDF reports with TOC, sections, and appendices
- **PowerPoint Integration**: Automated presentation creation with various slide types
- **Client Branding**: Custom styling and professional appearance
- **Extensible Templates**: Customizable page layouts and chart types

### üßπ **Code Hygiene (2 functions)**
- **Documentation**: Automated docstring generation and function analysis
- **Code Quality**: Code maintenance and quality assurance tools

### üß™ **Testing & Development (2 functions)**
- **Environment Setup**: Spark environment configuration and diagnostics
- **Development Tools**: Testing framework and development support

**Total Functions: 600+** | **Total Modules: 16** | **Coverage: 100%** | **Test Status: 158/158 passing**

## üé® **Modernization Benefits**

### **üöÄ Performance Improvements**
- **Better Error Handling**: Faster failure detection and recovery
- **Resource Management**: Proper cleanup of file handles and connections
- **Memory Efficiency**: Better memory management in file operations
- **Logging Optimization**: Structured logging with configurable levels

### **üõ°Ô∏è Reliability Enhancements**
- **Consistent Error Handling**: Standardized exception handling patterns
- **Graceful Degradation**: Better handling of missing dependencies
- **File Safety**: Safe file operations with proper cleanup
- **Network Resilience**: Retry logic and timeout handling for downloads

### **üîß Developer Experience**
- **Type Safety**: Full type hints for better IDE support and error detection
- **Clean APIs**: Consistent function signatures and return types
- **Comprehensive Testing**: 158 tests ensuring code quality
- **Better Documentation**: Detailed docstrings with examples
- **Modern Patterns**: Uses latest Python best practices

### **üìö Maintainability**
- **Modular Architecture**: Clear separation of concerns
- **Backward Compatibility**: Maintains existing API while improving internals
- **Code Consistency**: Uniform coding style throughout
- **Easy Testing**: Comprehensive test suite for regression prevention

## üì¶ **What's Included**

## üåü Unique Auto-Discovery System

Unlike traditional packages, Siege Utilities uses an **enhanced auto-discovery system**:

```python
# Traditional approach - lots of imports needed
from package.module1 import function_a
from package.module2 import function_b
from package.core.logging import log_info

def my_function():
    log_info("Starting process")
    result_a = function_a()
    result_b = function_b()

# Siege Utilities approach - everything just works
import siege_utilities

def my_function():
    log_info("Starting process")      # Available everywhere
    result_a = function_a()           # Available everywhere
    result_b = function_b()           # Available everywhere
```

### How It Works

1. **Phase 1**: Bootstrap core logging system
2. **Phase 2**: Import modules in dependency order
3. **Phase 3**: Auto-discover all `.py` files and subpackages
4. **Phase 4**: Inject all functions into all modules (mutual availability)
5. **Phase 5**: Provide comprehensive diagnostics

**Result**: 500+ functions accessible from anywhere with zero imports!

## üìä Package Diagnostics

Monitor your package health:

```python
import siege_utilities

# Get comprehensive package information
info = siege_utilities.get_package_info()
print(f"Total functions: {info['total_functions']}")
print(f"Loaded modules: {info['total_modules']}")
print(f"Failed imports: {info['failed_imports']}")

# List functions by pattern
log_functions = siege_utilities.list_available_functions("log_")
file_functions = siege_utilities.list_available_functions("file")

# Check dependencies
deps = siege_utilities.check_dependencies()
print(f"PySpark available: {deps['pyspark']}")
print(f"Geopy available: {deps['geopy']}")

# Get function information
func_info = siege_utilities.get_function_info("get_file_hash")
print(f"Function from module: {func_info['module']}")
```

## üîß Installation Options

```bash
# Basic installation
pip install siege-utilities

# With distributed computing support
pip install siege-utilities[distributed]

# With geospatial support
pip install siege-utilities[geo]

# Full installation (all optional dependencies)
pip install siege-utilities[distributed,geo,dev]

# Development installation
git clone https://github.com/siege-analytics/siege_utilities.git
cd siege_utilities
pip install -e ".[distributed,geo,dev]"
```

## üìñ Detailed Examples

### File Processing Pipeline

```python
import siege_utilities

def process_data_files(input_dir, output_dir):
    """Complete file processing pipeline using siege utilities."""

    # Setup with logging
    siege_utilities.init_logger("data_processor", log_to_file=True)
    siege_utilities.log_info(f"Starting processing: {input_dir} -> {output_dir}")

    # Ensure output directory exists
    siege_utilities.ensure_path_exists(output_dir)

    # Process each file
    for file_path in pathlib.Path(input_dir).glob("*.txt"):
        if siege_utilities.check_if_file_exists_at_path(file_path):

            # Generate file hash for integrity
            file_hash = siege_utilities.get_file_hash(file_path)
            siege_utilities.log_info(f"Processing {file_path.name}: {file_hash}")

            # Count rows and check for issues
            total_rows = siege_utilities.count_total_rows_in_file_using_sed(file_path)
            empty_rows = siege_utilities.count_empty_rows_in_file_using_awk(file_path)

            siege_utilities.log_info(f"File stats: {total_rows} total, {empty_rows} empty")

            # Process and save results
            output_path = output_dir / f"processed_{file_path.name}"
            # ... your processing logic here

    siege_utilities.log_info("Processing complete!")
```

### Client and Connection Management

```python
import siege_utilities

def setup_client_project():
    """Complete client and project setup using siege utilities."""
    
    # Create client profile with contact info and design artifacts
    contact_info = {
        "primary_contact": "Jane Smith",
        "email": "jane.smith@acmecorp.com",
        "phone": "+1-555-0123",
        "address": "123 Business Ave, Tech City, TC 12345"
    }
    
    client = siege_utilities.create_client_profile(
        "Acme Corporation",
        "ACME001",
        contact_info,
        industry="Technology",
        logo_path="/assets/logos/acme_logo.png",
        brand_colors=["#0066CC", "#FF6600"],
        data_format="parquet",
        report_style="executive"
    )
    
    # Create project configuration
    project = siege_utilities.create_project_config(
        "Acme Data Analytics Platform",
        "ACME001",
        description="Comprehensive analytics platform for Acme Corporation"
    )
    
    # Setup project directories
    siege_utilities.setup_project_directories(project)
    
    # Associate client with project
    siege_utilities.associate_client_with_project("ACME001", "ACME001")
    
    # Create and test connections
    notebook_conn = siege_utilities.create_connection_profile(
        "Acme Jupyter Lab",
        "notebook",
        {"url": "http://localhost:8888", "token": "abc123"}
    )
    
    spark_conn = siege_utilities.create_connection_profile(
        "Acme Spark Cluster",
        "spark",
        {"master_url": "spark://spark-master:7077"}
    )
    
    # Test connections
    notebook_result = siege_utilities.test_connection(notebook_conn['connection_id'])
    spark_result = siege_utilities.test_connection(spark_conn['connection_id'])
    
    if notebook_result['success'] and spark_result['success']:
        siege_utilities.log_info("All connections successful!")
    else:
        siege_utilities.log_warning("Some connections failed")
```

### Distributed Computing Workflow

```python
import siege_utilities

def distributed_geocoding_pipeline(data_path):
    """Distributed geocoding using Spark and HDFS."""

    # Check if distributed features are available
    deps = siege_utilities.check_dependencies()
    if not deps['pyspark']:
        siege_utilities.log_error("PySpark required for distributed processing")
        return

    # Setup distributed environment
    config = siege_utilities.create_cluster_config(data_path)
    spark, hdfs_path = siege_utilities.setup_distributed_environment(config)

    if spark and hdfs_path:
        siege_utilities.log_info(f"Distributed environment ready: {hdfs_path}")

        # Load and process data
        df = spark.read.parquet(hdfs_path)
        df = siege_utilities.sanitise_dataframe_column_names(df)
        df = siege_utilities.validate_geocode_data(df, "latitude", "longitude")

        # Geocoding operations
        geocoder = siege_utilities.NominatimGeoClassifier()
        # ... geocoding logic here

        # Save results
        output_path = hdfs_path.replace("input", "output")
        siege_utilities.write_df_to_parquet(df, output_path)

        spark.stop()
    else:
        siege_utilities.log_error("Failed to setup distributed environment")
```

## üß™ Testing & Quality Assurance

This package includes a comprehensive test suite designed to **ensure code quality** and maintain reliability across all 158 tests.

### Quick Test Run

```bash
# Basic functionality check (30 seconds)
python -m pytest tests/ --tb=short -q

# Or with verbose output
python -m pytest tests/ -v
```

### Test Installation

```bash
# Install test dependencies
pip install -r test_requirements.txt

# Or install with development extras
pip install -e ".[dev]"
```

### Test Categories

#### üî• Core Functionality Tests (Recommended First)
```bash
python -m pytest tests/test_core_logging.py -v      # 26 tests
python -m pytest tests/test_file_operations.py -v  # 46 tests
python -m pytest tests/test_file_remote.py -v      # 30 tests
python -m pytest tests/test_paths.py -v            # 3 tests
```
- **Purpose**: Test core functionality and file operations
- **Duration**: ~2 minutes
- **Coverage**: Essential operations and error handling

#### ‚ö° Quick Validation
```bash
python -m pytest tests/ --tb=short -q
```
- **Purpose**: Quick validation of all tests
- **Duration**: ~30 seconds
- **Best for**: Pre-commit checks and quick validation

#### üß™ Comprehensive Testing
```bash
python -m pytest tests/ -v
```
- **Purpose**: Run complete test suite with detailed output
- **Duration**: ~33 seconds
- **Includes**: All 158 tests with full reporting

#### üìä Coverage Analysis
```bash
python -m pytest tests/ --cov=siege_utilities --cov-report=html
```
- **Purpose**: Generate code coverage report
- **Duration**: ~1 minute
- **Output**: HTML coverage report in `htmlcov/`

### Module-Specific Testing

Test specific modules to focus on particular areas:

```bash
# Test core logging functionality
python -m pytest tests/test_core_logging.py -v

# Test file operations
python -m pytest tests/test_file_operations.py -v

# Test remote file operations
python -m pytest tests/test_file_remote.py -v

# Test path utilities
python -m pytest tests/test_paths.py -v

# Test specific function categories
python -m pytest tests/ -k "test_logging" -v
python -m pytest tests/ -k "test_file" -v
```

### Performance Options

```bash
# Parallel execution (requires pytest-xdist)
python -m pytest tests/ -n auto

# Verbose output for debugging
python -m pytest tests/ -v -s

# Stop after first failure
python -m pytest tests/ -x

# Run only tests that failed last time
python -m pytest tests/ --lf
```

### üêõ Expected Test Results

The tests are **designed to find issues**. Here's what to expect:

#### ‚úÖ **Should Pass**
- Package discovery and import mechanisms
- Basic string manipulation
- File hashing operations
- Path creation and management
- Geocoding (if geopy is installed)

#### ‚ùå **Known Issues** (Will Fail)
1. **File Operations**:
   - `count_total_rows_in_file_pythonically()` - **BUG**: Uses filename in loop instead of file handle
   - `count_empty_rows_in_file_pythonically()` - **BUG**: Same issue as above

2. **Shell Operations**:
   - Missing import for `io` module in `remove_empty_rows_in_file_using_sed()`
   - Undefined variables in error handling paths

3. **Distributed Computing**:
   - `move_column_to_front_of_dataframe()` - **BUG**: Returns original DataFrame instead of reordered one
   - Multiple functions use undefined variables like `RESULTS_OUTPUT_FORMAT`
   - Easter egg: `reproject_geom_columns()` prints "I LOVE LEENA" üéâ

#### ‚ö†Ô∏è **Conditional Tests**
- Spark utilities (require PySpark installation)
- Geocoding (requires geopy)
- Remote operations (require network access)

### Debugging Failed Tests

```bash
# Run specific test
pytest tests/test_file_operations.py::TestFileOperations::test_count_total_rows_in_file_pythonically_bug -v

# Run with debugging
pytest tests/test_file_operations.py -v -s --tb=long

# Focus on one module
pytest tests/test_core_*.py -v
```

### Test Reports

After running tests with coverage:

```bash
python -m pytest tests/ --cov=siege_utilities --cov-report=html
```

View reports:
- **HTML Coverage**: `htmlcov/index.html`
- **Test Report**: Available in terminal output
- **Coverage Summary**: Terminal summary with percentage

### üí° Testing Tips

1. **Start with Core Tests**: Always run core functionality tests first
2. **Fix High-Impact Issues**: Focus on functions that completely fail
3. **Test After Each Fix**: Re-run tests after making changes
4. **Use Verbose Mode**: When debugging specific issues
5. **Check Dependencies**: Some tests require optional packages

**Remember**: Finding issues is **success** - it means the tests are working! üî•

## üß™ **Testing & Development**

The package includes a comprehensive testing framework with **158 tests passing**:

### **Test Runner**
```bash
# Interactive test runner with pytest
python -m pytest tests/ -v

# Direct pytest execution
python -m pytest tests/ -v

# Run specific test categories
python -m pytest tests/ -k "logging"     # Logging tests
python -m pytest tests/ -k "file"        # File operation tests  
python -m pytest tests/ -k "remote"      # Remote file tests
python -m pytest tests/ -k "paths"       # Path utility tests

# Run with coverage and parallel execution
python -m pytest tests/ --cov=siege_utilities --cov-report=html
python -m pytest tests/ -n auto  # Parallel execution
```

### **Test Results & Status**
- **Total Tests**: 158
- **Passing**: 158 (100% success rate)
- **Coverage**: Comprehensive coverage across all modules
- **Test Duration**: ~33 seconds for full suite

### Test Structure

```
tests/
‚îú‚îÄ‚îÄ conftest.py                           # Shared test fixtures
‚îú‚îÄ‚îÄ test_client_and_connection_config.py  # Client & connection tests
‚îú‚îÄ‚îÄ test_core_logging.py                  # Logging system tests (26 tests)
‚îú‚îÄ‚îÄ test_file_operations.py               # File operation tests (46 tests)
‚îú‚îÄ‚îÄ test_file_remote.py                   # Remote file tests (30 tests)
‚îú‚îÄ‚îÄ test_geocoding.py                     # Geospatial tests
‚îú‚îÄ‚îÄ test_package_discovery.py             # Auto-discovery tests
‚îú‚îÄ‚îÄ test_paths.py                         # Path utility tests (3 tests)
‚îú‚îÄ‚îÄ test_shell.py                         # Shell command tests
‚îú‚îÄ‚îÄ test_spark_utils.py                   # Spark utility tests
‚îî‚îÄ‚îÄ test_string_utils.py                  # String utility tests
```

### Adding New Tests

To add tests for new functionality:

1. **Create test file**: `tests/test_new_feature.py`
2. **Follow naming convention**: Test classes should be named `TestFeatureName`
3. **Use descriptive test names**: `test_function_name_expected_behavior`
4. **Include edge cases**: Test error conditions and boundary cases
5. **Use fixtures**: Leverage `conftest.py` for shared test data

Example test structure:

```python
import pytest
from siege_utilities.new_feature import new_function

class TestNewFeature:
    """Test the new feature functionality."""
    
    def test_new_function_basic_usage(self):
        """Test basic functionality of new_function."""
        result = new_function("test_input")
        assert result == "expected_output"
    
    def test_new_function_with_invalid_input(self):
        """Test that new_function handles invalid input gracefully."""
        with pytest.raises(ValueError, match="Invalid input"):
            new_function("")
    
    def test_new_function_edge_case(self):
        """Test edge case behavior."""
        result = new_function(None)
        assert result is None
```

### Test Dependencies

Tests use these key dependencies:

- **pytest**: Main testing framework
- **pytest-cov**: Coverage reporting
- **pytest-xdist**: Parallel test execution
- **unittest.mock**: Mocking external dependencies

Install test dependencies:

```bash
pip install -r test_requirements.txt
```

### Continuous Integration

The package includes GitHub Actions for automated testing:

- **Python versions**: 3.8, 3.9, 3.10, 3.11, 3.12
- **Test coverage**: Minimum 90% coverage required
- **Code quality**: Flake8 and black formatting checks
- **Documentation**: Sphinx build verification

### Running Tests Locally

```bash
# Setup development environment
git clone https://github.com/siege-analytics/siege_utilities.git
cd siege_utilities
pip install -e ".[dev]"

# Run tests
pytest

# Run with specific Python version
python3.9 -m pytest

# Run tests and generate coverage report
pytest --cov=siege_utilities --cov-report=term-missing
```

### Debugging Tests

```bash
# Run single test with verbose output
pytest tests/test_client_and_connection_config.py::TestClientConfiguration::test_create_client_profile_basic -v -s

# Run tests with debugger
pytest --pdb

# Run tests and show local variables on failure
pytest --tb=short --showlocals
```

## üèóÔ∏è Development

### Documentation

The package includes comprehensive Sphinx documentation that automatically builds and deploys to GitHub Pages, plus extensive recipe collections covering all major use cases.

#### Multi-Engine Recipes & Examples

**Engine Agnostic Processing:**
- **Batch Processing**: `MultiEngineBatchProcessor` for scalable file operations with automatic engine selection
- **Data Processing**: `MultiEngineDataProcessor` for unified data loading and transformation across engines
- **Analytics**: `MultiEngineAnalyticsProcessor` for cross-platform data collection and analysis
- **Database**: `SparkDatabaseManager` for Spark + Sedona database integration with spatial operations
- **Mapping**: `ConfigurableMapGenerator` with SVG marker support and multiple visualization backends

**Recipe Collections:**
- **`wiki_fresh/`**: Latest multi-engine recipes with comprehensive examples
- **`wiki_recipes/`**: Curated recipe collections organized by use case
- **`wiki_debug/`**: Troubleshooting guides and debugging recipes

**Key Multi-Engine Features:**
- Automatic engine selection based on data size and operation complexity
- Performance benchmarking across Pandas and Spark
- Hybrid processing workflows combining both engines
- Unified API for consistent development experience
- Comprehensive error handling and fallback mechanisms

#### Building Documentation Locally

```bash
# Navigate to docs directory
cd docs

# Fast build (recommended for development)
make fast

# Full build (complete documentation)
make full

# Standard build (optimized)
make html

# Clean build directory
make clean
```

#### Documentation Build Performance

**If documentation builds are slow** (taking 5+ minutes), use the fast build option:

```bash
cd docs
make fast  # Completes in 30 seconds - 2 minutes
```

**Performance optimizations applied:**
- Disabled AutoAPI extension (was processing 500+ functions)
- Disabled member generation and inheritance diagrams
- Disabled type hint processing
- Disabled source code copying
- Disabled search index generation

**When to use each build type:**
- **`make fast`**: During development, quick checks
- **`make full`**: Before releases, complete documentation
- **`make html`**: Standard build (now optimized)

#### Troubleshooting Slow Builds

1. **Stop slow builds**: Press `Ctrl+C` in terminal
2. **Clean build directory**: `make clean` before rebuilding
3. **Use fast build**: `make fast` for development
4. **Monitor progress**: `make html SPHINXOPTS="-v"`

#### Documentation Structure

```
docs/
‚îú‚îÄ‚îÄ source/
‚îÇ   ‚îú‚îÄ‚îÄ index.rst                    # Main documentation page
‚îÇ   ‚îú‚îÄ‚îÄ testing_guide.rst           # Comprehensive testing guide
‚îÇ   ‚îú‚îÄ‚îÄ autodiscovery.rst           # Auto-discovery system
‚îÇ   ‚îú‚îÄ‚îÄ all_functions.rst           # Complete function listing
‚îÇ   ‚îú‚îÄ‚îÄ conf.py                     # Main Sphinx configuration
‚îÇ   ‚îú‚îÄ‚îÄ conf_fast.py                # Fast build configuration
‚îÇ   ‚îî‚îÄ‚îÄ api/                        # API reference
‚îî‚îÄ‚îÄ build/                          # Generated documentation
```

#### Documentation Deployment

Documentation automatically builds and deploys to GitHub Pages via GitHub Actions:

1. **Edit RST files** in `docs/source/`
2. **Build locally** to test: `make fast`
3. **Commit and push** changes to GitHub
4. **GitHub Actions** automatically rebuilds and deploys to `https://siege-analytics.github.io/siege_utilities/`

### Adding New Functions

Just create a new `.py` file anywhere in the package:

```python
# siege_utilities/my_new_module.py

def my_awesome_function(data):
    """This function will be auto-discovered!"""
    log_info("my_awesome_function called")  # Logging available automatically

    # All other siege utilities functions are available
    file_hash = get_file_hash(data)  # No import needed!
    ensure_path_exists("output")     # No import needed!

    return f"processed_{file_hash}"

def another_function():
    """This will also be auto-discovered!"""
    return "Hello from auto-discovery!"
```

**That's it!** Next time you import siege_utilities, these functions will be automatically available:

```python
import siege_utilities

# Your new functions are automatically available
result = siege_utilities.my_awesome_function("data.txt")
greeting = siege_utilities.another_function()

# And they're mutually available in other modules too!
```

### Running Diagnostics

```bash
# Check package health (run from package directory)
python3 check_imports.py

# Or from Python
python3 -c "
import siege_utilities
info = siege_utilities.get_package_info()
print(f'Functions: {info[\"total_functions\"]}')
print(f'Modules: {info[\"total_modules\"]}')
print(f'Failed: {len(info[\"failed_imports\"])}')
"
```

### Development Workflow

1. **Add new functions** to existing modules or create new ones
2. **Test with diagnostics**: `python3 check_imports.py`
3. **Run comprehensive tests**: `python -m pytest tests/ -v`
4. **Fix any issues** found by tests
5. **Run specific test modules**: `python -m pytest tests/test_core_logging.py -v`
6. **Check test coverage**: `python -m pytest tests/ --cov=siege_utilities --cov-report=html`
7. **Run quick smoke test**: `python -m pytest tests/ --tb=short -q`

### Testing Best Practices

Our comprehensive test suite ensures code quality:

- **158 tests** covering all major modules
- **Modern pytest framework** with detailed reporting
- **Type safety validation** through comprehensive testing
- **Backward compatibility** testing for all legacy functions
- **Error handling validation** for robust error scenarios
- **Integration testing** for complex workflows

### Test Categories

```bash
# Core functionality tests
python -m pytest tests/test_core_logging.py -v      # 26 tests
python -m pytest tests/test_file_operations.py -v  # 46 tests
python -m pytest tests/test_file_remote.py -v      # 30 tests
python -m pytest tests/test_paths.py -v            # 3 tests

# All tests with coverage
python -m pytest tests/ --cov=siege_utilities --cov-report=html

# Quick validation
python -m pytest tests/ --tb=short -q
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Add your functions to existing modules or create new ones
4. **Run tests**: `python -m pytest tests/ --tb=short -q`
5. Test with: `python3 check_imports.py`
6. Commit changes: `git commit -am 'Add new feature'`
7. Push: `git push origin feature-name`
8. Submit a Pull Request

The auto-discovery system will automatically find and integrate your new functions!

## üìù License

MIT License - see LICENSE file for details.

## üôè Acknowledgments

- Built by [Siege Analytics](https://github.com/siege-analytics)
- Inspired by the need for truly seamless Python utilities
- Special thanks to the auto-discovery pattern that makes this possible

---

**Siege Utilities**: Spatial Intelligence, In Python! üöÄ
