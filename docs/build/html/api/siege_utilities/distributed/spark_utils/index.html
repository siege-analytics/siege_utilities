

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>siege_utilities.distributed.spark_utils &mdash; Siege Utilities 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=a12e3537"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            Siege Utilities
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../autodiscovery.html">Enhanced Auto-Discovery System</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../autodiscovery.html#how-it-works">How It Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autodiscovery.html#the-five-phase-discovery-process">The Five-Phase Discovery Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autodiscovery.html#benefits">Benefits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autodiscovery.html#monitoring-your-package">Monitoring Your Package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autodiscovery.html#adding-new-functions">Adding New Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../all_functions.html">Complete Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-core-logging">siege_utilities.core.logging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-core-string-utils">siege_utilities.core.string_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-distributed-hdfs-config">siege_utilities.distributed.hdfs_config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-distributed-hdfs-legacy">siege_utilities.distributed.hdfs_legacy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-distributed-hdfs-operations">siege_utilities.distributed.hdfs_operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-distributed-spark-utils">siege_utilities.distributed.spark_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-files-hashing">siege_utilities.files.hashing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-files-operations">siege_utilities.files.operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-files-paths">siege_utilities.files.paths</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-files-remote">siege_utilities.files.remote</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-files-shell">siege_utilities.files.shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../all_functions.html#siege-utilities-geo-geocoding">siege_utilities.geo.geocoding</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing_guide.html">Testing Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#test-structure">Test Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#running-tests">Running Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#basic-test-execution">Basic Test Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-runner-script">Test Runner Script</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#coverage-and-reporting">Coverage and Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#parallel-execution">Parallel Execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#test-markers">Test Markers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#writing-new-tests">Writing New Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-file-structure">Test File Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-naming-conventions">Test Naming Conventions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#example-test-patterns">Example Test Patterns</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#test-fixtures">Test Fixtures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#test-configuration">Test Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#pytest-configuration">Pytest Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#coverage-configuration">Coverage Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#continuous-integration">Continuous Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#ci-pipeline">CI Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#debugging-tests">Debugging Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#verbose-output">Verbose Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#debug-mode">Debug Mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#single-test-execution">Single Test Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-isolation">Test Isolation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#performance-testing">Performance Testing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#benchmark-tests">Benchmark Tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#load-testing">Load Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#test-data-management">Test Data Management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-data-generation">Test Data Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#data-cleanup">Data Cleanup</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#best-practices">Best Practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-organization">Test Organization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-independence">Test Independence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#test-coverage">Test Coverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#performance-considerations">Performance Considerations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#common-patterns">Common Patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#configuration-testing">Configuration Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#file-operation-testing">File Operation Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#api-testing">API Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#troubleshooting">Troubleshooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../testing_guide.html#common-issues">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../testing_guide.html#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Siege Utilities</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">siege_utilities.distributed.spark_utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-siege_utilities.distributed.spark_utils">
<span id="siege-utilities-distributed-spark-utils"></span><h1>siege_utilities.distributed.spark_utils<a class="headerlink" href="#module-siege_utilities.distributed.spark_utils" title="Link to this heading"></a></h1>
<section id="attributes">
<h2>Attributes<a class="headerlink" href="#attributes" title="Link to this heading"></a></h2>
</section>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h2>
</section>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.atomic_write_with_staging">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">atomic_write_with_staging</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_destination</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">staging_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'csv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delimiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">','</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">header</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'overwrite'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.atomic_write_with_staging" title="Link to this definition"></a></dt>
<dd><p>Performs atomic write operations using a staging directory to prevent partial/corrupted files.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.backup_full_dataframe">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">backup_full_dataframe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.backup_full_dataframe" title="Link to this definition"></a></dt>
<dd><p>“””
Utility function: backup full dataframe.</p>
<p>Part of Siege Utilities Utilities module.
Auto-discovered and available at package level.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Description needed</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">siege_utilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">siege_utilities</span><span class="o">.</span><span class="n">backup_full_dataframe</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is auto-discovered and available without imports
across all siege_utilities modules.</p>
</div>
<p>“””</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.clean_and_reorder_bbox">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">clean_and_reorder_bbox</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bbox_col</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.clean_and_reorder_bbox" title="Link to this definition"></a></dt>
<dd><p>Removes brackets from bounding box strings and reorders coordinates for Sedona.</p>
<dl class="simple">
<dt>Assumes input is a comma separated list in the order:</dt><dd><p>min latitude, max latitude, min longitude, max longitude</p>
</dd>
</dl>
<p>Produces an array in the order: [min_lon, min_lat, max_lon, max_lat]</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.compute_walkability">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">compute_walkability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">distance</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.compute_walkability" title="Link to this definition"></a></dt>
<dd><p>“””
Utility function: compute walkability.</p>
<p>Part of Siege Utilities Utilities module.
Auto-discovered and available at package level.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Description needed</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">siege_utilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">siege_utilities</span><span class="o">.</span><span class="n">compute_walkability</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is auto-discovered and available without imports
across all siege_utilities modules.</p>
</div>
<p>“””</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.create_unique_staging_directory">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">create_unique_staging_directory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">operation_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'operation'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.create_unique_staging_directory" title="Link to this definition"></a></dt>
<dd><p>Creates a unique staging directory for atomic operations.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.ensure_literal">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">ensure_literal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.ensure_literal" title="Link to this definition"></a></dt>
<dd><p>Convert any value to a Spark literal (Column) unless it is already a Spark Column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> – Any value to be converted.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A pyspark.sql.Column containing the value (or its Spark literal),
unless the value is already a Column.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.export_prepared_df_as_csv_to_path_using_delimiter">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">export_prepared_df_as_csv_to_path_using_delimiter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">write_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pathlib.Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delimiter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">','</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.export_prepared_df_as_csv_to_path_using_delimiter" title="Link to this definition"></a></dt>
<dd><p>Exports DataFrame <strong>with necessary transformations</strong> to ensure Spark compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – Target DataFrame</p></li>
<li><p><strong>write_path</strong> – Pathlib object for export destination</p></li>
<li><p><strong>delimiter</strong> – CSV delimiter (default is comma)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>bool indicating success/failure</p>
</dd>
</dl>
<p>Applies <cite>prepare_dataframe_for_export()</cite> to prevent Spark export issues.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.export_pyspark_df_to_excel">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">export_pyspark_df_to_excel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'output.xlsx'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sheet_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Sheet1'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.export_pyspark_df_to_excel" title="Link to this definition"></a></dt>
<dd><p>Converts a PySpark DataFrame to a Pandas DataFrame and exports it to an Excel file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>spark_df</strong> (<em>pyspark.sql.DataFrame</em>) – The PySpark DataFrame to export.</p></li>
<li><p><strong>file_name</strong> (<em>str</em>) – The name of the output Excel file.</p></li>
<li><p><strong>sheet_name</strong> (<em>str</em>) – The sheet name in the Excel file.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.flatten_json_column_and_join_back_to_df">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">flatten_json_column_and_join_back_to_df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">json_column</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'json_column_'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_original</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explode_arrays</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flatten_level</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'shallow'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.DataFrame</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.flatten_json_column_and_join_back_to_df" title="Link to this definition"></a></dt>
<dd><p>Flattens a JSON column in a Spark DataFrame, extracting fields and adding them as columns.
Has fallback mechanisms for corrupt JSON data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – The input Spark DataFrame.</p></li>
<li><p><strong>json_column</strong> (<em>str</em>) – The name of the column containing JSON strings.</p></li>
<li><p><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – Prefix to add to the flattened column names. Defaults to “<a href="#id1"><span class="problematic" id="id2">json_column_</span></a>”.</p></li>
<li><p><strong>logger</strong> (<em>Optional</em><em>[</em><em>any</em><em>]</em><em>, </em><em>optional</em>) – Logger object for logging messages. Defaults to None.</p></li>
<li><p><strong>drop_original</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to drop the original JSON column after flattening. Defaults to True.</p></li>
<li><p><strong>explode_arrays</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to explode array columns. Defaults to False.</p></li>
<li><p><strong>flatten_level</strong> (<em>str</em><em>, </em><em>optional</em>) – “shallow” or “deep” flattening. Defaults to “shallow”.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) – Controls whether to log detailed messages. Defaults to False.</p></li>
<li><p><strong>sample_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of samples to check. Defaults to 5.</p></li>
<li><p><strong>show_samples</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to display sample data. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The DataFrame with the JSON column flattened.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.get_row_count">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">get_row_count</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.get_row_count" title="Link to this definition"></a></dt>
<dd><p>Returns the count of rows in the dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>df</strong> (<em>DataFrame</em>) – Input Spark DataFrame.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Row count or None if an error occurred.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.mark_valid_geocode_data">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">mark_valid_geocode_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lat_col_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lon_col_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_col_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'is_valid'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.mark_valid_geocode_data" title="Link to this definition"></a></dt>
<dd><p>Adds a boolean flag column to the DataFrame indicating whether the geographic coordinates are valid.</p>
<p>A set of coordinates is considered valid if:
- The latitude and longitude columns are not null.
- The latitude is between -90 and 90.
- The longitude is between -180 and 180.</p>
<p>Unlike filtering functions, this function preserves all rows in the DataFrame by simply marking
each row with a True (valid) or False (invalid) value in the new output column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – The Spark DataFrame containing geocode data.</p></li>
<li><p><strong>lat_col_name</strong> (<em>str</em>) – The name of the latitude column.</p></li>
<li><p><strong>lon_col_name</strong> (<em>str</em>) – The name of the longitude column.</p></li>
<li><p><strong>output_col_name</strong> (<em>str</em><em>, </em><em>optional</em>) – The name of the output column to store the validity flag.
Defaults to “is_valid”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new DataFrame with an additional column indicating geocode validity.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.move_column_to_front_of_dataframe">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">move_column_to_front_of_dataframe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">column_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.move_column_to_front_of_dataframe" title="Link to this definition"></a></dt>
<dd><p>“””
Utility function: move column to front of dataframe.</p>
<p>Part of Siege Utilities Utilities module.
Auto-discovered and available at package level.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Description needed</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">siege_utilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">siege_utilities</span><span class="o">.</span><span class="n">move_column_to_front_of_dataframe</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is auto-discovered and available without imports
across all siege_utilities modules.</p>
</div>
<p>“””</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.pivot_summary_table_for_bools">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">pivot_summary_table_for_bools</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spark</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.pivot_summary_table_for_bools" title="Link to this definition"></a></dt>
<dd><p>Generate a pivot table summary for given boolean flag columns in a DataFrame.
The pivot table includes three metrics:</p>
<blockquote>
<div><ul class="simple">
<li><p>“Count”: Sum of rows where the flag is True.</p></li>
<li><p>“Percentage (%)”: Percentage relative to total records.</p></li>
<li><p>“Total”: The total number of records (repeated for each column).</p></li>
</ul>
</div></blockquote>
<p>All numeric values are converted to float to ensure a consistent type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – The source Spark DataFrame.</p></li>
<li><p><strong>columns</strong> (<em>list</em>) – List of column names (assumed to be boolean flags) to summarize.</p></li>
<li><p><strong>spark</strong> (<em>SparkSession</em>) – The active Spark session.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Spark DataFrame representing the pivot table.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.pivot_summary_with_metrics">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">pivot_summary_with_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pivot_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spark</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.pivot_summary_with_metrics" title="Link to this definition"></a></dt>
<dd><p>Generate a pivot summary for a categorical column against one or more grouping columns,
including rows for “Count”, “Percentage (%)”, and “Total” for each group.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – The source Spark DataFrame.</p></li>
<li><p><strong>group_col</strong> (<em>str</em><em> or </em><em>list</em>) – The column name (or list of column names) used for grouping.
For example, “geocode_granularity” or [“state”, “region”].</p></li>
<li><p><strong>pivot_col</strong> (<em>str</em>) – The categorical column to pivot on (e.g., “final_geocode_choice”).</p></li>
<li><p><strong>spark</strong> (<em>SparkSession</em>) – The active Spark session.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Spark DataFrame in which each original group appears as three rows:</dt><dd><p>one for the counts, one for the percentages, and one for the total count.
The non-grouping columns represent each distinct pivot column value.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.prepare_dataframe_for_export">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">prepare_dataframe_for_export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.prepare_dataframe_for_export" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Prepares a DataFrame for export (e.g., to CSV) by:</dt><dd><ul class="simple">
<li><p>Converting binary columns to Base64-encoded strings.</p></li>
<li><p>Casting simple scalar fields (non-string, non-complex) to strings.</p></li>
<li><p>Dropping intermediate columns (e.g., ‘parsed_json’) if present.</p></li>
<li><p>Converting complex (StructType/ArrayType) columns to JSON strings.</p></li>
<li><p>Handling null values appropriately.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – Spark DataFrame to prepare</p></li>
<li><p><strong>logger_func</strong> – Optional logging function (defaults to print)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The transformed DataFrame with all columns as strings or JSON strings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.prepare_summary_dataframe">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">prepare_summary_dataframe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_tuples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">column_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['metric',</span> <span class="pre">'value']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.prepare_summary_dataframe" title="Link to this definition"></a></dt>
<dd><p>Helper function to create summary DataFrames with consistent string types.
Prevents type merging errors by ensuring all values are strings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_tuples</strong> – List of tuples with data</p></li>
<li><p><strong>column_names</strong> – Column names for the DataFrame</p></li>
<li><p><strong>logger_func</strong> – Optional logging function</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Spark DataFrame with all string columns</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.print_debug_table">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">print_debug_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark_df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.print_debug_table" title="Link to this definition"></a></dt>
<dd><p>Helper function to convert a Spark DataFrame into a Pandas DataFrame,
format it using tabulate, and print the result with a title.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.read_parquet_to_df">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">read_parquet_to_df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.SparkSession</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.read_parquet_to_df" title="Link to this definition"></a></dt>
<dd><p>Reads a Parquet file into a Spark DataFrame.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>spark</strong> (<em>SparkSession</em>) – Active Spark session.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – Path to the Parquet file.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loaded DataFrame or None if an error occurred.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.register_temp_table">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">register_temp_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">table_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.register_temp_table" title="Link to this definition"></a></dt>
<dd><p>Registers a temporary view from a dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – Input Spark DataFrame.</p></li>
<li><p><strong>table_name</strong> (<em>str</em>) – Name for the temporary view.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if successful, False otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.repartition_and_cache">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">repartition_and_cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.repartition_and_cache" title="Link to this definition"></a></dt>
<dd><p>Repartitions and caches a dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – Input Spark DataFrame.</p></li>
<li><p><strong>partitions</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of partitions. Default is 100.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Repartitioned and cached DataFrame or None if an error occurred.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.reproject_geom_columns">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">reproject_geom_columns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">geom_columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_srid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_srid</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.reproject_geom_columns" title="Link to this definition"></a></dt>
<dd><p>Reprojects geometry columns using the three-argument version of ST_Transform:
ST_Transform(geom, ‘source_srid’, ‘target_srid’)</p>
<p>Only reprojects if the current SRID is not equal to the target.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – Spark DataFrame containing the geometry columns.</p></li>
<li><p><strong>geom_columns</strong> (<em>list</em>) – List of column names (strings) to reproject.</p></li>
<li><p><strong>source_srid</strong> (<em>str</em>) – The source CRS (e.g. “EPSG:4326”).</p></li>
<li><p><strong>target_srid</strong> (<em>str</em>) – The target CRS (e.g. “EPSG:27700”).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The DataFrame with each specified geometry column conditionally reprojected.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.sanitise_dataframe_column_names">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">sanitise_dataframe_column_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.sanitise_dataframe_column_names" title="Link to this definition"></a></dt>
<dd><p>Cleans dataframe column names by converting them to lowercase and replacing
slashes/spaces with underscores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>df</strong> (<em>DataFrame</em>) – Input Spark DataFrame.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sanitised DataFrame or None if an error occurred.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.tabulate_null_vs_not_null">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">tabulate_null_vs_not_null</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">column_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.tabulate_null_vs_not_null" title="Link to this definition"></a></dt>
<dd><p>Returns a dataframe showing the count of null and non-null values for a given column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – Input Spark DataFrame.</p></li>
<li><p><strong>column_name</strong> (<em>str</em>) – Name of the column to analyze.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Resulting DataFrame with null vs non-null counts.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.validate_geocode_data">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">validate_geocode_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lat_col_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lon_col_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.validate_geocode_data" title="Link to this definition"></a></dt>
<dd><p>Filters out rows with invalid geographic coordinates using string-based column names.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.validate_geometry">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">validate_geometry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">geom_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.validate_geometry" title="Link to this definition"></a></dt>
<dd><p>Validates a single geometry column.</p>
<p>Parameters:
- df (DataFrame): Spark DataFrame containing geometry data.
- geom_col (str): Name of the geometry column to check.
- step_name (str): Label for the debug output.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.write_df_to_parquet">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">write_df_to_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'overwrite'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.write_df_to_parquet" title="Link to this definition"></a></dt>
<dd><p>Writes a DataFrame to a Parquet file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>DataFrame</em>) – Input Spark DataFrame.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – Output path.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Write mode. Defaults to “overwrite”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if successful, False otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.PYSPARK_AVAILABLE">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">PYSPARK_AVAILABLE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#siege_utilities.distributed.spark_utils.PYSPARK_AVAILABLE" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.logger">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">logger</span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.logger" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.new_walkability_udf">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">new_walkability_udf</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#siege_utilities.distributed.spark_utils.new_walkability_udf" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="siege_utilities.distributed.spark_utils.walkability_config">
<span class="sig-prename descclassname"><span class="pre">siege_utilities.distributed.spark_utils.</span></span><span class="sig-name descname"><span class="pre">walkability_config</span></span><a class="headerlink" href="#siege_utilities.distributed.spark_utils.walkability_config" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Dheeraj Chand.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>